# Pipeline de Dados Serverless na AWS para Coleta de Dados Financeiros

## üìñ Vis√£o Geral do Projeto

Este projeto implementa um pipeline de dados 100% serverless na nuvem da AWS para automatizar a coleta, armazenamento e an√°lise de dados financeiros. A solu√ß√£o foi projetada para ser de baixo custo, escal√°vel e de baixa manuten√ß√£o, utilizando as melhores pr√°ticas de engenharia de dados na nuvem.

O pipeline coleta diariamente a cota√ß√£o do D√≥lar (PTAX) a partir da API p√∫blica do Banco Central do Brasil e armazena os dados em um Data Lake no Amazon S3, tornando-os dispon√≠veis para consulta via SQL.

## üèóÔ∏è Arquitetura da Solu√ß√£o

A arquitetura foi constru√≠da utilizando os seguintes servi√ßos da AWS, que interagem de forma orquestrada para compor o fluxo de dados:

<img width="1024" height="1024" alt="image" src="https://github.com/user-attachments/assets/b5235e52-7931-435c-ac65-14f22d616473" />


**Fluxo de Dados:**
1.  **Amazon EventBridge:** Atua como o orquestrador (scheduler), disparando o pipeline em uma agenda pr√©-definida (ex: duas vezes ao dia).
2.  **AWS Lambda:** O cora√ß√£o do pipeline. Uma fun√ß√£o Python √© executada para fazer a requisi√ß√£o √† API externa, processar os dados e salv√°-los no S3.
3.  **Amazon S3:** Serve como um Data Lake centralizado, armazenando os arquivos JSON com os dados coletados de forma dur√°vel e econ√¥mica.
4.  **AWS Glue Crawler:** Um rastreador que escaneia automaticamente os dados no S3, infere o esquema (colunas e tipos de dados) e cria uma tabela no Cat√°logo de Dados do Glue.
5.  **Amazon Athena:** Permite a execu√ß√£o de consultas SQL padr√£o diretamente nos arquivos armazenados no S3, utilizando o esquema do Cat√°logo de Dados do Glue para fornecer respostas r√°pidas e sob demanda.

## ‚ú® Features

* **100% Serverless:** Nenhum servidor para gerenciar, com custo zero quando o pipeline n√£o est√° em execu√ß√£o.
* **Automa√ß√£o Completa:** O agendamento via EventBridge garante que os dados sejam coletados sem qualquer interven√ß√£o manual.
* **Descoberta de Esquema Autom√°tica:** O Glue Crawler adapta o cat√°logo de dados a poss√≠veis mudan√ßas no formato dos arquivos.
* **An√°lise via SQL:** Permite que analistas e cientistas de dados consultem os dados brutos usando uma linguagem familiar e poderosa.

## üõ†Ô∏è Tecnologias Utilizadas

* **Cloud:** AWS (Amazon Web Services)
* **Linguagem:** Python 3
* **Principais Servi√ßos AWS:**
    * AWS Lambda
    * Amazon S3
    * Amazon EventBridge
    * AWS Glue (Crawler & Data Catalog)
    * Amazon Athena
    * AWS IAM (Identity and Access Management)

## üöÄ Como Executar (Setup)

Para replicar este projeto, os seguintes passos s√£o necess√°rios:

1.  **Configurar um Bucket S3:** Criar um bucket para servir como Data Lake.
2.  **Criar a Fun√ß√£o Lambda:** Fazer o upload do c√≥digo `lambda_function.py` e configurar as vari√°veis de ambiente (como o nome do bucket) e as permiss√µes do IAM.
3.  **Criar o Crawler do Glue:** Apontar o crawler para o bucket S3 e configurar um banco de dados de destino.
4.  **Configurar a Regra do EventBridge:** Criar um agendamento para acionar a fun√ß√£o Lambda na frequ√™ncia desejada.

---
*Este projeto foi desenvolvido como um estudo pr√°tico de engenharia de dados na AWS. Desenvolvido por Jo√£o V√≠tor Sgotti Veiga.*
